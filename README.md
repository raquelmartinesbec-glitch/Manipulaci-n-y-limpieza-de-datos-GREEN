# ğŸŒ¿ Proyecto de AnÃ¡lisis y Limpieza de Datos - GreenMart Dataset

Este repositorio contiene un flujo de trabajo completo para el anÃ¡lisis, manipulaciÃ³n y limpieza de datos basado en el dataset de GreenMart, una cadena de retail especializada en productos ecolÃ³gicos.

## ğŸ“‹ DescripciÃ³n del Proyecto

El proyecto se centra en el anÃ¡lisis de patrones de compra de clientes y productos de GreenMart, implementando tÃ©cnicas de limpieza de datos, anÃ¡lisis exploratorio y generaciÃ³n de datasets ficticios para preservar la confidencialidad de la informaciÃ³n real.

### ğŸ”’ Confidencialidad, Privacidad y AnonimizaciÃ³n de Datos

**IMPORTANTE**: Este repositorio implementa **anonimizaciÃ³n completa** y NO contiene datos reales de clientes o transacciones. Los datos sintÃ©ticos se han generado porque **los datos reales de GreenMart no pueden ser compartidos** por razones de confidencialidad empresarial y cumplimiento de normativas de privacidad:

- âœ… **Los datos reales estÃ¡n protegidos** y no pueden salir del entorno empresarial
- âœ… Se utilizan exclusivamente **datos ficticios completamente anonimizados** como alternativa
- âœ… Los datos ficticios **replican la estructura** del dataset real sin comprometer informaciÃ³n sensible
- âœ… **EliminaciÃ³n total** de nombres, direcciones, informaciÃ³n financiera o datos personales reales
- âœ… **CÃ³digos anÃ³nimos** reemplazan cualquier identificador personal
- âœ… El generador de datos sintÃ©ticos utiliza **identificadores no trazables**

## ğŸ¯ Origen y GeneraciÃ³n de Datos

### ğŸ“Š Â¿De dÃ³nde provienen los datos?
**CONTEXTO IMPORTANTE**: Los datos reales de GreenMart no pueden ser compartidos por polÃ­ticas de confidencialidad empresarial y normativas de privacidad. Por esta razÃ³n, los datos utilizados en este proyecto son **100% sintÃ©ticos** y se generan usando:

- **ğŸ² Algoritmos matemÃ¡ticos**: Distribuciones estadÃ­sticas controladas
- **ğŸ­ LibrerÃ­a Faker**: GeneraciÃ³n de datos ficticios realistas pero no reales
- **ğŸ”¢ NumPy Random**: NÃºmeros aleatorios con semillas controladas
- **ğŸ“… Fechas sintÃ©ticas**: Rangos temporales ficticios de los Ãºltimos 2 aÃ±os
- **ğŸ’° Valores econÃ³micos**: Precios y cantidades dentro de rangos lÃ³gicos

### ğŸ”„ Proceso de GeneraciÃ³n:
1. **ProtecciÃ³n de datos reales**: Los datos originales permanecen en el entorno empresarial
2. **DefiniciÃ³n de estructura**: Columnas y tipos de datos esperados (sin datos reales)
3. **GeneraciÃ³n algorÃ­tmica**: CreaciÃ³n de registros sintÃ©ticos que replican patrones
4. **AplicaciÃ³n de reglas**: LÃ³gica de negocio para datos coherentes pero inventados
5. **AnonimizaciÃ³n**: CÃ³digos y IDs no trazables
6. **ExportaciÃ³n**: Archivo CSV listo para procesamiento acadÃ©mico/educativo

### ğŸ“ Flujo de Archivos:
```
Datos Reales GreenMart (PROTEGIDOS/NO COMPARTIDOS) 
           â†“ 
    Estructura Replicada
           â†“
Algoritmos SintÃ©ticos â†’ data_generator.py â†’ greenmart_customers_products.csv â†’ preprocessing.py â†’ greenmart_dataset_limpio.csv
```

## ğŸ—‚ï¸ Estructura del Proyecto

```
Proyecto_Analisis_GREEN/
â”œâ”€â”€ ğŸ““ notebooks/                    # Jupyter Notebooks para anÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 01_analisis_inicial.ipynb   # AnÃ¡lisis exploratorio y generaciÃ³n de datos
â”‚   â””â”€â”€ Limpieza_de_dataset_Green.ipynb  # Proceso detallado de limpieza de datos
â”œâ”€â”€ ğŸ scripts/                     # Scripts de procesamiento y generaciÃ³n
â”‚   â”œâ”€â”€ data_generator.py           # Generador de datos ficticios
â”‚   â””â”€â”€ preprocessing.py            # Script de limpieza sin funciones (estructura lineal)
â”œâ”€â”€ ğŸ“Š data/                        # Datasets ficticios generados
â”‚   â”œâ”€â”€ greenmart_customers_products.csv (generado localmente)
â”‚   â””â”€â”€ greenmart_dataset_limpio.csv (resultado del preprocesamiento)
â”œâ”€â”€ ğŸ“‹ reports/                     # Informes y documentaciÃ³n
â”œâ”€â”€ ğŸ”§ .gitignore                   # ConfiguraciÃ³n de archivos ignorados
â”œâ”€â”€ ğŸ“ README.md                    # Este archivo
â””â”€â”€ ğŸ“¦ requirements.txt             # Dependencias del proyecto
```

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos Previos
- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### 1. ConfiguraciÃ³n del Entorno
```bash
# Clonar el repositorio
git clone <url-del-repositorio>
cd Proyecto_Analisis_GREEN

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Generar Datos SintÃ©ticos (ORIGEN DE LOS DATOS)
```bash
# PASO 1: Ejecutar el generador de datos sintÃ©ticos
python scripts/data_generator.py
```
**ğŸ” Â¿De dÃ³nde vienen los datos?**
- ğŸš« **Datos reales protegidos**: Los datos originales de GreenMart no pueden ser compartidos
- âœ… **100% sintÃ©ticos**: Generados por algoritmos usando la librerÃ­a `Faker`
- âœ… **Sin fuente real**: No provienen de ningÃºn dataset real o base de datos
- âœ… **Completamente ficticios**: Creados matemÃ¡ticamente para simular patrones
- âœ… **Guardados en**: `data/greenmart_customers_products.csv`

### 3. Ejecutar Limpieza de Datos
```bash
# PASO 2: Procesar y limpiar datos sintÃ©ticos
python scripts/preprocessing.py
```
**ğŸ“Š Flujo de datos:**
- ğŸ“¥ **Entrada**: `data/greenmart_customers_products.csv` (datos sintÃ©ticos)
- ğŸ§¹ **Procesamiento**: Limpieza, normalizaciÃ³n y anonimizaciÃ³n
- ğŸ“¤ **Salida**: `data/greenmart_dataset_limpio.csv` (datos procesados)

### 4. AnÃ¡lisis Exploratorio
```bash
# PASO 3: AnÃ¡lisis interactivo
jupyter notebook notebooks/01_analisis_inicial.ipynb
```

## ğŸ“Š Estructura del Dataset AnÃ³nimo

El dataset generado contiene las siguientes columnas **completamente anonimizadas**:

| Columna | Tipo | DescripciÃ³n | Estado de AnonimizaciÃ³n |
|---------|------|-------------|-------------------------|
| `customer_name` | string | ID de cliente anonimizado (CUSTOMER_XXXXXX) | ğŸš« Eliminado en limpieza |
| `age` | integer | Rango de edad ficticio | ğŸš« Eliminado en limpieza |
| `city` | string | CÃ³digo de ciudad anÃ³nimo (CITY_XXXX) | ğŸš« Eliminado en limpieza |
| `purchase_date` | date | Fecha de compra ficticia | âœ… Transformado a variables temporales |
| `purchase_quantity` | integer | Cantidad de productos (normalizado) | âœ… Normalizado |
| `price_per_unit` | float | Precio por unidad (normalizado) | âœ… Normalizado |
| `total_spent` | float | Total gastado (normalizado) | âœ… Normalizado |
| `product_name` | string | CÃ³digo de producto anÃ³nimo (PROD_ECO001) | âœ… Codificado numÃ©ricamente |
| `category` | string | CÃ³digo de categorÃ­a anÃ³nimo (CAT_A) | âœ… Codificado numÃ©ricamente |

## ğŸ§¹ Proceso de Limpieza de Datos

El pipeline de limpieza sigue una **estructura secuencial sin funciones**, implementando los siguientes pasos:

### 1. **ExploraciÃ³n Inicial**
- VisualizaciÃ³n de primeras filas con `df.head()`
- InformaciÃ³n de tipos de datos con `df.info()`
- EstadÃ­sticas descriptivas con `df.describe()`
- Listado de columnas disponibles

### 2. **IdentificaciÃ³n de Valores Faltantes**
- AnÃ¡lisis con `df.isnull().sum()`
- IdentificaciÃ³n de patrones de datos ausentes

### 3. **EliminaciÃ³n de Datos Sensibles**
- **AnonimizaciÃ³n completa**: EliminaciÃ³n de toda informaciÃ³n personal identificable
- Columnas removidas por privacidad: `customer_name`, `age`, `city`
- **Cumplimiento GDPR**: Sin datos que permitan identificar individuos

### 4. **Manejo de Duplicados**
- Conteo con `df.duplicated().sum()`
- EliminaciÃ³n con `df.drop_duplicates()`

### 5. **NormalizaciÃ³n de Fechas**
- ConversiÃ³n a formato datetime con `pd.to_datetime()`
- ExtracciÃ³n de caracterÃ­sticas temporales:
  - `year`: AÃ±o de la compra
  - `month`: Mes de la compra
  - `day`: DÃ­a de la compra
  - `weekday`: DÃ­a de la semana (0=Lunes)
- EliminaciÃ³n de la columna fecha original

### 6. **EstandarizaciÃ³n NumÃ©rica**
- AplicaciÃ³n de `StandardScaler` (media=0, desviaciÃ³n=1)
- Variables normalizadas: `purchase_quantity`, `price_per_unit`, `total_spent`

### 7. **CodificaciÃ³n CategÃ³rica**
- AplicaciÃ³n de `LabelEncoder` para convertir categorÃ­as en nÃºmeros Ãºnicos
- Variables codificadas: `product_name`, `category`

### 8. **Guardado del Dataset Limpio**
- ExportaciÃ³n como `greenmart_dataset_limpio.csv`

## ğŸ” CaracterÃ­sticas del AnÃ¡lisis

- **AnonimizaciÃ³n Total**: EliminaciÃ³n completa de datos personales identificables
- **Estructura Lineal**: CÃ³digo secuencial sin funciones para facilitar comprensiÃ³n y modificaciÃ³n
- **AnÃ¡lisis Exploratorio**: EstadÃ­sticas descriptivas, distribuciones y patrones
- **Calidad de Datos**: IdentificaciÃ³n de inconsistencias y valores atÃ­picos
- **Transformaciones**: NormalizaciÃ³n y codificaciÃ³n de variables
- **Reproducibilidad**: Pipeline claro y documentado paso a paso
- **Cumplimiento de Privacidad**: Sin informaciÃ³n trazable a individuos reales

## ğŸ›¡ï¸ Consideraciones de Seguridad

- Los datos ficticios se generan usando librerÃ­as como `Faker` para crear informaciÃ³n realista pero no real
- No se almacenan credenciales ni informaciÃ³n sensible en el repositorio
- El `.gitignore` estÃ¡ configurado para excluir archivos de configuraciÃ³n locales
- El dataset limpio se genera localmente y no se incluye en el control de versiones

## ğŸ¤ Contribuciones

Este proyecto estÃ¡ diseÃ±ado para fines educativos y de anÃ¡lisis. Las contribuciones son bienvenidas siguiendo las mejores prÃ¡cticas de desarrollo colaborativo.

## ğŸ“„ Licencia

Proyecto desarrollado con fines acadÃ©micos y de aprendizaje en manipulaciÃ³n y limpieza de datos.

---

*âš ï¸ Recordatorio: Este repositorio contiene Ãºnicamente datos ficticios. Cualquier similitud con personas o transacciones reales es pura coincidencia.*
